# Railway Anomaly Detection - Environment Configuration
# Copy this to .env and modify as needed

# =============================================================================
# Backend Configuration
# =============================================================================

# Server settings
HOST=0.0.0.0
PORT=8000
DEBUG=true

# =============================================================================
# Neo4j Graph Database
# =============================================================================

# Default connection (local Docker)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# For Neo4j Aura (cloud):
# NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=your-aura-password

# =============================================================================
# MinIO Object Storage (S3-Compatible)
# =============================================================================

# Local MinIO (Docker)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=railadmin
MINIO_SECRET_KEY=railsecret123
MINIO_SECURE=false

# Bucket names
MINIO_BUCKET_FRAMES=railway-frames
MINIO_BUCKET_UPLOADS=railway-uploads
MINIO_BUCKET_REPORTS=railway-reports

# =============================================================================
# Ollama LLM Configuration
# =============================================================================

# Local Ollama server
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Alternative models:
# OLLAMA_MODEL=llama3:8b
# OLLAMA_MODEL=mistral
# OLLAMA_MODEL=codellama

# =============================================================================
# Google Gemini API (Optional alternative to Ollama)
# =============================================================================

# If set, the backend can use Gemini for chat.
# DO NOT commit real keys.
# GOOGLE_API_KEY=your_api_key_here

# =============================================================================
# YOLO Model Configuration
# =============================================================================

# Use GPU if available
USE_GPU=true

# Model confidence threshold
YOLO_CONFIDENCE=0.5

# =============================================================================
# Optional: External Services
# =============================================================================

# MQTT (if using real-time feeds)
# MQTT_BROKER=localhost
# MQTT_PORT=1883

# Redis (if using caching)
# REDIS_URL=redis://localhost:6379
