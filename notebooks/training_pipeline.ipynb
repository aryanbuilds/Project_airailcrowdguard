{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Railway Track Anomaly Detection - Training Notebook\n",
                "\n",
                "This notebook provides an end-to-end guide for:\n",
                "1. Environment setup and installation\n",
                "2. Dataset exploration\n",
                "3. Training TWO YOLOv8 models (Binary + Detailed)\n",
                "4. Model evaluation and visualization\n",
                "5. Cascade inference testing\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup & Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install ultralytics opencv-python pillow pyyaml matplotlib --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify installation\n",
                "import ultralytics\n",
                "ultralytics.checks()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import os\n",
                "import cv2\n",
                "import yaml\n",
                "import random\n",
                "import shutil\n",
                "from pathlib import Path\n",
                "from ultralytics import YOLO\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "\n",
                "# Set working directory to project root\n",
                "PROJECT_ROOT = Path(\".\").absolute()\n",
                "print(f\"Project Root: {PROJECT_ROOT}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Exploration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset paths\n",
                "DATASETS = {\n",
                "    \"binary\": PROJECT_ROOT / \"data\" / \"Railway Track Fault detection.v4i.yolov8\",\n",
                "    \"detailed\": PROJECT_ROOT / \"data\" / \"Railway Track Defect Detection.v1i.yolov8\"\n",
                "}\n",
                "\n",
                "# Check datasets exist\n",
                "for name, path in DATASETS.items():\n",
                "    exists = path.exists()\n",
                "    print(f\"{name}: {'Found' if exists else 'NOT FOUND'} - {path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and display data.yaml for each dataset\n",
                "def show_dataset_info(dataset_name):\n",
                "    yaml_path = DATASETS[dataset_name] / \"data.yaml\"\n",
                "    with open(yaml_path, 'r') as f:\n",
                "        data = yaml.safe_load(f)\n",
                "    \n",
                "    print(f\"\\n=== {dataset_name.upper()} Dataset ===\")\n",
                "    print(f\"Number of classes: {data['nc']}\")\n",
                "    print(f\"Classes: {data['names']}\")\n",
                "    \n",
                "    # Count images\n",
                "    train_dir = DATASETS[dataset_name] / \"train\" / \"images\"\n",
                "    if train_dir.exists():\n",
                "        train_count = len(list(train_dir.glob(\"*\")))\n",
                "        print(f\"Training images: {train_count}\")\n",
                "\n",
                "show_dataset_info(\"binary\")\n",
                "show_dataset_info(\"detailed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample images from each dataset\n",
                "def show_samples(dataset_name, num_samples=4):\n",
                "    img_dir = DATASETS[dataset_name] / \"train\" / \"images\"\n",
                "    images = list(img_dir.glob(\"*.jpg\")) + list(img_dir.glob(\"*.png\"))\n",
                "    samples = random.sample(images, min(len(images), num_samples))\n",
                "    \n",
                "    fig, axes = plt.subplots(1, num_samples, figsize=(16, 4))\n",
                "    fig.suptitle(f\"{dataset_name.upper()} Dataset Samples\", fontsize=14)\n",
                "    \n",
                "    for ax, img_path in zip(axes, samples):\n",
                "        img = Image.open(img_path)\n",
                "        ax.imshow(img)\n",
                "        ax.set_title(img_path.name[:20])\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "show_samples(\"binary\")\n",
                "show_samples(\"detailed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Training\n",
                "\n",
                "We train TWO models:\n",
                "1. **Binary Model**: Defective vs Non-Defective (fast filter)\n",
                "2. **Detailed Model**: 9 specific defect types with severity levels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Train Binary Model (Stage 1 - Fast Filter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration for Binary Model\n",
                "BINARY_CONFIG = {\n",
                "    \"data\": str(DATASETS[\"binary\"] / \"data.yaml\"),\n",
                "    \"epochs\": 50,\n",
                "    \"imgsz\": 640,\n",
                "    \"batch\": 16,  # Reduce if you get OOM errors\n",
                "    \"project\": \"runs/detect\",\n",
                "    \"name\": \"train_binary\",\n",
                "    \"exist_ok\": True\n",
                "}\n",
                "\n",
                "print(\"Binary Model Configuration:\")\n",
                "for k, v in BINARY_CONFIG.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Binary Model\n",
                "print(\"Loading base model (yolov8n)...\")\n",
                "binary_model = YOLO(\"yolov8n.pt\")\n",
                "\n",
                "print(\"Starting Binary Model Training...\")\n",
                "print(\"This may take 30-60 minutes depending on your hardware.\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "binary_results = binary_model.train(**BINARY_CONFIG)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"Binary Model Training Complete!\")\n",
                "print(f\"Results saved to: {binary_results.save_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Train Detailed Model (Stage 2 - Classification)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration for Detailed Model\n",
                "DETAILED_CONFIG = {\n",
                "    \"data\": str(DATASETS[\"detailed\"] / \"data.yaml\"),\n",
                "    \"epochs\": 50,\n",
                "    \"imgsz\": 640,\n",
                "    \"batch\": 16,\n",
                "    \"project\": \"runs/detect\",\n",
                "    \"name\": \"train_detailed\",\n",
                "    \"exist_ok\": True\n",
                "}\n",
                "\n",
                "print(\"Detailed Model Configuration:\")\n",
                "for k, v in DETAILED_CONFIG.items():\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train Detailed Model\n",
                "print(\"Loading base model (yolov8n)...\")\n",
                "detailed_model = YOLO(\"yolov8n.pt\")\n",
                "\n",
                "print(\"Starting Detailed Model Training...\")\n",
                "print(\"This may take 30-60 minutes depending on your hardware.\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "detailed_results = detailed_model.train(**DETAILED_CONFIG)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"Detailed Model Training Complete!\")\n",
                "print(f\"Results saved to: {detailed_results.save_dir}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Copy Trained Weights to Models Folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create models directory and copy weights\n",
                "models_dir = PROJECT_ROOT / \"models\"\n",
                "models_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# Copy Binary weights\n",
                "binary_weights = Path(\"runs/detect/train_binary/weights/best.pt\")\n",
                "if binary_weights.exists():\n",
                "    shutil.copy(binary_weights, models_dir / \"binary_model.pt\")\n",
                "    print(f\"Copied: {binary_weights} -> models/binary_model.pt\")\n",
                "else:\n",
                "    print(f\"Warning: {binary_weights} not found\")\n",
                "\n",
                "# Copy Detailed weights\n",
                "detailed_weights = Path(\"runs/detect/train_detailed/weights/best.pt\")\n",
                "if detailed_weights.exists():\n",
                "    shutil.copy(detailed_weights, models_dir / \"detailed_model.pt\")\n",
                "    print(f\"Copied: {detailed_weights} -> models/detailed_model.pt\")\n",
                "else:\n",
                "    print(f\"Warning: {detailed_weights} not found\")\n",
                "\n",
                "print(\"\\nModels directory contents:\")\n",
                "for f in models_dir.glob(\"*.pt\"):\n",
                "    print(f\"  - {f.name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load trained models\n",
                "binary_model = YOLO(\"models/binary_model.pt\")\n",
                "detailed_model = YOLO(\"models/detailed_model.pt\")\n",
                "\n",
                "print(\"Models loaded successfully!\")\n",
                "print(f\"Binary model classes: {binary_model.names}\")\n",
                "print(f\"Detailed model classes: {detailed_model.names}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate Binary Model\n",
                "print(\"Validating Binary Model...\")\n",
                "binary_val = binary_model.val(data=str(DATASETS[\"binary\"] / \"data.yaml\"))\n",
                "print(f\"mAP50: {binary_val.box.map50:.4f}\")\n",
                "print(f\"mAP50-95: {binary_val.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate Detailed Model\n",
                "print(\"Validating Detailed Model...\")\n",
                "detailed_val = detailed_model.val(data=str(DATASETS[\"detailed\"] / \"data.yaml\"))\n",
                "print(f\"mAP50: {detailed_val.box.map50:.4f}\")\n",
                "print(f\"mAP50-95: {detailed_val.box.map:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Cascade Inference Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_severity(class_name):\n",
                "    \"\"\"Extract severity from class name.\"\"\"\n",
                "    if \"high\" in class_name.lower():\n",
                "        return \"HIGH\"\n",
                "    elif \"medium\" in class_name.lower():\n",
                "        return \"MEDIUM\"\n",
                "    elif \"low\" in class_name.lower():\n",
                "        return \"LOW\"\n",
                "    return \"UNKNOWN\"\n",
                "\n",
                "\n",
                "def cascade_inference(image_path, binary_model, detailed_model, threshold=0.5):\n",
                "    \"\"\"\n",
                "    Run two-stage cascade inference.\n",
                "    Stage 1: Binary check (defective / non-defective)\n",
                "    Stage 2: Detailed classification (only if defective)\n",
                "    \"\"\"\n",
                "    \n",
                "    # Stage 1: Binary\n",
                "    binary_result = binary_model(image_path, conf=threshold, verbose=False)\n",
                "    boxes = binary_result[0].boxes\n",
                "    \n",
                "    if boxes is None or len(boxes) == 0:\n",
                "        return {\n",
                "            \"status\": \"non-defective\",\n",
                "            \"confidence\": 0.0,\n",
                "            \"stage\": 1\n",
                "        }\n",
                "    \n",
                "    max_conf = float(boxes.conf.max())\n",
                "    \n",
                "    if max_conf < threshold:\n",
                "        return {\n",
                "            \"status\": \"non-defective\",\n",
                "            \"confidence\": max_conf,\n",
                "            \"stage\": 1\n",
                "        }\n",
                "    \n",
                "    # Stage 2: Detailed\n",
                "    detailed_result = detailed_model(image_path, conf=0.25, verbose=False)\n",
                "    detailed_boxes = detailed_result[0].boxes\n",
                "    \n",
                "    if detailed_boxes is None or len(detailed_boxes) == 0:\n",
                "        return {\n",
                "            \"status\": \"defective\",\n",
                "            \"defect_type\": \"unknown\",\n",
                "            \"severity\": \"UNKNOWN\",\n",
                "            \"confidence\": max_conf,\n",
                "            \"stage\": 2\n",
                "        }\n",
                "    \n",
                "    best_idx = detailed_boxes.conf.argmax()\n",
                "    class_id = int(detailed_boxes.cls[best_idx])\n",
                "    class_name = detailed_result[0].names[class_id]\n",
                "    conf = float(detailed_boxes.conf[best_idx])\n",
                "    \n",
                "    return {\n",
                "        \"status\": \"defective\",\n",
                "        \"defect_type\": class_name,\n",
                "        \"severity\": extract_severity(class_name),\n",
                "        \"confidence\": conf,\n",
                "        \"stage\": 2\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test cascade inference on sample images\n",
                "test_images_dir = DATASETS[\"detailed\"] / \"test\" / \"images\"\n",
                "test_images = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.png\"))\n",
                "\n",
                "print(f\"Found {len(test_images)} test images\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "# Test on random samples\n",
                "samples = random.sample(test_images, min(10, len(test_images)))\n",
                "\n",
                "for img_path in samples:\n",
                "    result = cascade_inference(str(img_path), binary_model, detailed_model)\n",
                "    \n",
                "    if result[\"status\"] == \"non-defective\":\n",
                "        print(f\"[OK] {img_path.name}: Non-defective (conf: {result['confidence']:.2f})\")\n",
                "    else:\n",
                "        print(f\"[!!] {img_path.name}: {result['defect_type']} | Severity: {result['severity']} | Conf: {result['confidence']:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize cascade results\n",
                "def visualize_cascade_result(image_path, binary_model, detailed_model):\n",
                "    \"\"\"Visualize the cascade inference result.\"\"\"\n",
                "    result = cascade_inference(str(image_path), binary_model, detailed_model)\n",
                "    \n",
                "    # Get annotated image from detailed model\n",
                "    detailed_result = detailed_model(str(image_path), verbose=False)\n",
                "    annotated = detailed_result[0].plot()\n",
                "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    plt.imshow(annotated_rgb)\n",
                "    \n",
                "    title = f\"Status: {result['status'].upper()}\"\n",
                "    if result['status'] == 'defective':\n",
                "        title += f\" | Type: {result['defect_type']} | Severity: {result['severity']}\"\n",
                "    title += f\" | Conf: {result['confidence']:.2f}\"\n",
                "    \n",
                "    plt.title(title, fontsize=12)\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "\n",
                "# Visualize a few samples\n",
                "for img_path in random.sample(test_images, min(3, len(test_images))):\n",
                "    visualize_cascade_result(img_path, binary_model, detailed_model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Summary & Next Steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"TRAINING COMPLETE - SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(\"\\nTrained Models:\")\n",
                "print(\"  1. Binary Model: models/binary_model.pt\")\n",
                "print(\"     Classes: defective, non-defective\")\n",
                "print(\"     Purpose: Fast filter\")\n",
                "\n",
                "print(\"\\n  2. Detailed Model: models/detailed_model.pt\")\n",
                "print(\"     Classes: 9 defect types with severity\")\n",
                "print(\"     Purpose: Classification\")\n",
                "\n",
                "print(\"\\nCascade Pipeline:\")\n",
                "print(\"  Image -> Binary Model -> (if defective) -> Detailed Model -> Result\")\n",
                "\n",
                "print(\"\\nNext Steps:\")\n",
                "print(\"  1. Start FastAPI backend: uvicorn backend.main:app --reload\")\n",
                "print(\"  2. Start Next.js frontend: cd frontend && npm run dev\")\n",
                "print(\"  3. Expose with ngrok: ngrok http 3000\")\n",
                "print(\"  4. Test on mobile!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}